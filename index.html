<!DOCTYPE html>
<html lang="en">
<head>
    <meta charset="UTF-8">
    <meta name="viewport" content="width=device-width, initial-scale=1.0">
    <title>YOLOv5s ONNX Demo in Browser</title>
    <style>
        body {
            font-family: -apple-system, BlinkMacSystemFont, "Segoe UI", Roboto, Helvetica, Arial, sans-serif;
            margin: 2rem;
            background-color: #f9f9f9;
            color: #333;
            display: flex;
            flex-direction: column;
            align-items: center;
        }
        h1 {
            color: #1a1a1a;
        }
        #loader {
            border: 8px solid #f3f3f3;
            border-top: 8px solid #3498db;
            border-radius: 50%;
            width: 60px;
            height: 60px;
            animation: spin 1s linear infinite;
            margin: 20px 0;
        }
        @keyframes spin {
            0% { transform: rotate(0deg); }
            100% { transform: rotate(360deg); }
        }
        .container {
            max-width: 800px;
            width: 100%;
            background: white;
            padding: 2rem;
            border-radius: 8px;
            box-shadow: 0 4px 6px rgba(0,0,0,0.1);
        }
        canvas {
            max-width: 100%;
            height: auto;
            border: 1px solid #ddd;
            border-radius: 4px;
            margin-top: 1rem;
        }
        .input-area {
            display: flex;
            flex-direction: column;
            align-items: center;
            gap: 1rem;
        }
        input[type="file"] {
            padding: 8px 12px;
            border: 1px solid #ccc;
            border-radius: 4px;
            cursor: pointer;
        }
        #status {
            margin-top: 1rem;
            font-weight: bold;
            color: #555;
        }
    </style>
</head>
<body>

    <div class="container">
        <h1>YOLOv5s ONNX Inference on Edge</h1>
        <p>
            This demo runs the YOLOv5s object detection model directly in your browser using ONNX Runtime.
            No data is sent to a server.
        </p>
        <div class="input-area">
            <div id="loader" style="display: none;"></div>
            <p id="status">Loading Model... Please Wait.</p>
            <input type="file" id="image-input" accept="image/*" disabled>
        </div>
        <canvas id="output-canvas"></canvas>
    </div>

    <!-- ONNX Runtime Web CDN -->
    <script src="https://cdn.jsdelivr.net/npm/onnxruntime-web/dist/ort.min.js"></script>

    <script>
        const modelPath = "./yolov5s.onnx";
        const imageInput = document.getElementById('image-input');
        const canvas = document.getElementById('output-canvas');
        const ctx = canvas.getContext('2d');
        const loader = document.getElementById('loader');
        const statusText = document.getElementById('status');
        let session;

        // COCO class names
        const classNames = [
            'person', 'bicycle', 'car', 'motorcycle', 'airplane', 'bus', 'train', 'truck', 'boat', 'traffic light',
            'fire hydrant', 'stop sign', 'parking meter', 'bench', 'bird', 'cat', 'dog', 'horse', 'sheep', 'cow',
            'elephant', 'bear', 'zebra', 'giraffe', 'backpack', 'umbrella', 'handbag', 'tie', 'suitcase', 'frisbee',
            'skis', 'snowboard', 'sports ball', 'kite', 'baseball bat', 'baseball glove', 'skateboard', 'surfboard',
            'tennis racket', 'bottle', 'wine glass', 'cup', 'fork', 'knife', 'spoon', 'bowl', 'banana', 'apple',
            'sandwich', 'orange', 'broccoli', 'carrot', 'hot dog', 'pizza', 'donut', 'cake', 'chair', 'couch',
            'potted plant', 'bed', 'dining table', 'toilet', 'tv', 'laptop', 'mouse', 'remote', 'keyboard', 'cell phone',
            'microwave', 'oven', 'toaster', 'sink', 'refrigerator', 'book', 'clock', 'vase', 'scissors', 'teddy bear',
            'hair drier', 'toothbrush'
        ];

        async function main() {
            try {
                // Set wasm backend
                ort.env.wasm.wasmPaths = 'https://cdn.jsdelivr.net/npm/onnxruntime-web/dist/';
                session = await ort.InferenceSession.create(modelPath);
                statusText.textContent = "Model loaded. Select an image.";
                imageInput.disabled = false;
            } catch (error) {
                console.error("Error loading model:", error);
                statusText.textContent = "Failed to load model. Check console for details.";
            }
        }

        imageInput.addEventListener('change', async (e) => {
            const file = e.target.files[0];
            if (!file) return;

            loader.style.display = 'block';
            statusText.textContent = 'Processing image...';

            const image = new Image();
            image.src = URL.createObjectURL(file);
            image.onload = async () => {
                const preprocessedData = preprocess(image);
                const inputTensor = new ort.Tensor('float32', preprocessedData, [1, 3, 640, 640]);

                try {
                    const feeds = { images: inputTensor };
                    const results = await session.run(feeds);
                    const outputData = results.output0;

                    // Draw image on canvas
                    canvas.width = image.width;
                    canvas.height = image.height;
                    ctx.drawImage(image, 0, 0, image.width, image.height);

                    // Post-process and draw boxes
                    processOutput(outputData, image.width, image.height);
                    statusText.textContent = 'Detection complete!';
                } catch (error) {
                    console.error("Error during inference:", error);
                    statusText.textContent = "Error during detection. Check console.";
                } finally {
                    loader.style.display = 'none';
                }
            };
        });

        function preprocess(img) {
            const canvas = document.createElement('canvas');
            canvas.width = 640;
            canvas.height = 640;
            const ctx = canvas.getContext('2d');
            ctx.drawImage(img, 0, 0, 640, 640);
            const imageData = ctx.getImageData(0, 0, 640, 640);
            const data = imageData.data;
            
            const red = [], green = [], blue = [];
            for (let i = 0; i < data.length; i += 4) {
                red.push(data[i] / 255.0);
                green.push(data[i + 1] / 255.0);
                blue.push(data[i + 2] / 255.0);
            }
            return [...red, ...green, ...blue];
        }

        function processOutput(output, imgWidth, imgHeight) {
            const boxes = [];
            // The output tensor has shape [1, 84, 8400]. 
            // 84 = x, y, w, h, and 80 class scores.
            // 8400 = number of potential detections.
            const numDetections = output.dims[2]; // Should be 8400
            const numClasses = 80;
            const stride = numDetections;

            for (let i = 0; i < numDetections; i++) {
                // The 5th row (index 4) contains the object confidence score
                const confidence = output.data[4 * stride + i];

                if (confidence > 0.45) { // Confidence threshold
                    let maxProb = 0;
                    let classId = 0;
                    // Iterate through the 80 class scores for this detection
                    for (let j = 0; j < numClasses; j++) {
                        const prob = output.data[(5 + j) * stride + i];
                        if (prob > maxProb) {
                            maxProb = prob;
                            classId = j;
                        }
                    }

                    if (maxProb > 0.5) { // Class probability threshold
                        const centerX = output.data[0 * stride + i];
                        const centerY = output.data[1 * stride + i];
                        const width = output.data[2 * stride + i];
                        const height = output.data[3 * stride + i];

                        boxes.push({
                            classId: classId,
                            probability: maxProb,
                            bounding: [
                                centerX - width / 2, // x1
                                centerY - height / 2, // y1
                                width,
                                height,
                            ],
                        });
                    }
                }
            }

            // Non-Maximum Suppression (NMS)
            const nmsThreshold = 0.45;
            const finalBoxes = [];
            boxes.sort((a, b) => b.probability - a.probability);

            while (boxes.length > 0) {
                finalBoxes.push(boxes[0]);
                const boxA = boxes.shift();
                for (let i = boxes.length - 1; i >= 0; i--) {
                    const boxB = boxes[i];
                    if (boxA.classId === boxB.classId) {
                        if (iou(boxA.bounding, boxB.bounding) > nmsThreshold) {
                            boxes.splice(i, 1);
                        }
                    }
                }
            }
            
            // Draw final boxes
            finalBoxes.forEach(box => drawBoundingBox(box, imgWidth, imgHeight));
        }

        function iou(boxA, boxB) {
            const xA = Math.max(boxA[0], boxB[0]);
            const yA = Math.max(boxA[1], boxB[1]);
            const xB = Math.min(boxA[0] + boxA[2], boxB[0] + boxB[2]);
            const yB = Math.min(boxA[1] + boxA[3], boxB[1] + boxB[3]);

            const interArea = Math.max(0, xB - xA) * Math.max(0, yB - yA);
            const boxAArea = boxA[2] * boxA[3];
            const boxBArea = boxB[2] * boxB[3];

            return interArea / (boxAArea + boxBArea - interArea);
        }

        function drawBoundingBox(box, imgWidth, imgHeight) {
            const xRatio = imgWidth / 640;
            const yRatio = imgHeight / 640;

            const [x1, y1, width, height] = box.bounding;
            
            ctx.strokeStyle = '#00FF00';
            ctx.lineWidth = 2;
            ctx.strokeRect(x1 * xRatio, y1 * yRatio, width * xRatio, height * yRatio);
            
            const label = `${classNames[box.classId]} (${(box.probability * 100).toFixed(1)}%)`;
            ctx.fillStyle = '#00FF00';
            ctx.font = '14px Arial';
            ctx.textBaseline = 'top';
            ctx.fillText(label, x1 * xRatio, y1 * yRatio - 14);
        }

        main();
    </script>
</body>

</html>



